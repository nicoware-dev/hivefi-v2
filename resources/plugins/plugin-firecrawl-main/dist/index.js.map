{"version":3,"sources":["../src/actions/getSearchData.ts","../src/environment.ts","../src/examples.ts","../src/services.ts","../src/templates.ts","../src/actions/getScrapeData.ts","../src/utils.ts","../src/index.ts"],"sourcesContent":["import {\n    elizaLogger,\n    Action,\n    ActionExample,\n    HandlerCallback,\n    IAgentRuntime,\n    Memory,\n    State,\n    generateText,\n    composeContext,\n    parseJSONObjectFromText,\n} from \"@elizaos/core\";\nimport { validateFirecrawlConfig } from \"../environment\";\nimport { getSearchDataExamples } from \"../examples\";\nimport { createFirecrawlService } from \"../services\";\nimport { searchDataPrompt } from \"../templates\";\nimport { ModelClass } from \"@elizaos/core\";\n\nexport const getSearchDataAction: Action = {\n    name: \"WEB_SEARCH\",\n    similes: [\n        \"SEARCH_WEB\",\n        \"INTERNET_SEARCH\",\n        \"LOOKUP\",\n        \"QUERY_WEB\",\n        \"FIND_ONLINE\",\n        \"SEARCH_ENGINE\",\n        \"WEB_LOOKUP\",\n        \"ONLINE_SEARCH\",\n        \"FIND_INFORMATION\",\n    ],\n    description:\n        \"Perform a web search to find information related to the message.\",\n    validate: async (runtime: IAgentRuntime) => {\n        await validateFirecrawlConfig(runtime);\n        return true;\n    },\n    handler: async (\n        runtime: IAgentRuntime,\n        message: Memory,\n        state: State,\n        _options: { [key: string]: unknown },\n        callback: HandlerCallback\n    ) => {\n        const config = await validateFirecrawlConfig(runtime);\n        const firecrawlService = createFirecrawlService(\n            config.FIRECRAWL_API_KEY\n        );\n\n        console.log(message.content.text);\n        try {\n            const messageText = message.content.text || \"\";\n\n            elizaLogger.info(`Found data: ${messageText}`);\n            const searchData =\n                await firecrawlService.getSearchData(messageText);\n\n            elizaLogger.success(`Successfully fectched data`);\n\n            const responseText = await generateText({\n                runtime,\n                context: `This was the user question: ${message.content.text}\n\n                        The Response data from firecrawl Search API is given below\n\n                        ${JSON.stringify(searchData)}\n\n                        Now Summarise and use this data and provide a response to question asked in the format.\n                        Note: The response should be in the same language as the question asked and should be human readable and make sense to the user\n                        Do not add any other text or comments to the response just the answer to the question\n                        Remove \\n \\r, special characters and html tags from the response\n                        `,\n                modelClass: ModelClass.SMALL,\n                customSystemPrompt: searchDataPrompt,\n            });\n\n            console.log(\"responseText\", responseText);\n\n            // const parsedResponse = parseJSONObjectFromText(responseText);\n\n            // console.log(\"parsedResponse\", parsedResponse);\n\n            if (callback) {\n                callback({\n                    text: `${JSON.stringify(responseText)}`,\n                });\n                return true;\n            }\n        } catch (error: any) {\n            elizaLogger.error(\"Error in the Firecrawl plugin\", error);\n            callback({\n                text: `Error fetching crawl data: ${error.message}`,\n                content: { error: error.message },\n            });\n            return false;\n        }\n    },\n    examples: getSearchDataExamples as ActionExample[][],\n} as Action;\n","// fc-1c97436691454d6c802bd82c2507e55c\n\nimport { IAgentRuntime } from \"@elizaos/core\";\nimport { z } from \"zod\";\n\nexport const firecrawlEnvSchema = z.object({\n    FIRECRAWL_API_KEY: z.string().min(1, \"Firecrawl API key is required\"),\n});\n\nexport type firecrawlConfig = z.infer<typeof firecrawlEnvSchema>;\n\nexport async function validateFirecrawlConfig(\n    runtime: IAgentRuntime\n): Promise<firecrawlConfig> {\n    try {\n        const config = {\n            FIRECRAWL_API_KEY: runtime.getSetting(\"FIRECRAWL_API_KEY\"),\n        };\n        console.log(\"config: \", config);\n        return firecrawlEnvSchema.parse(config);\n    } catch (error) {\n        console.log(\"error::::\", error);\n        if (error instanceof z.ZodError) {\n            const errorMessages = error.errors\n                .map((err) => `${err.path.join(\".\")}: ${err.message}`)\n                .join(\"\\n\");\n            throw new Error(\n                `Firecrawl API configuration validation failed:\\n${errorMessages}`\n            );\n        }\n        throw error;\n    }\n}\n","import { ActionExample } from \"@elizaos/core\";\n\nexport const getScrapedDataExamples: ActionExample[][] = [\n    [\n        {\n            user: \"{{user1}}\",\n            content: {\n                text: \"Can you scrape the content from https://example.com?\",\n            },\n        },\n        {\n            user: \"{{agent}}\",\n            content: {\n                text: \"I'll scrape the content from that website for you.\",\n                action: \"FIRECRAWL_GET_SCRAPED_DATA\",\n            },\n        },\n    ],\n    [\n        {\n            user: \"{{user1}}\",\n            content: {\n                text: \"Get the data from www.example.com/page\",\n            },\n        },\n        {\n            user: \"{{agent}}\",\n            content: {\n                text: \"I'll scrape the data from that webpage for you.\",\n                action: \"FIRECRAWL_GET_SCRAPED_DATA\",\n            },\n        },\n    ],\n    [\n        {\n            user: \"{{user1}}\",\n            content: {\n                text: \"I need to scrape some website data.\",\n            },\n        },\n        {\n            user: \"{{agent}}\",\n            content: {\n                text: \"I can help you scrape website data. Please share the URL you'd like me to process.\",\n            },\n        },\n        {\n            user: \"{{user1}}\",\n            content: {\n                text: \"example.com/products\",\n            },\n        },\n        {\n            user: \"{{agent}}\",\n            content: {\n                text: \"I'll scrape that webpage and get the data for you.\",\n                action: \"FIRECRAWL_GET_SCRAPED_DATA\",\n            },\n        },\n    ],\n];\n\nexport const getSearchDataExamples: ActionExample[][] = [\n    [\n        {\n            user: \"{{user1}}\",\n            content: {\n                text: \"Find the latest news about SpaceX launches.\",\n            },\n        },\n        {\n            user: \"{{agentName}}\",\n            content: {\n                text: \"Here is the latest news about SpaceX launches:\",\n                action: \"WEB_SEARCH\",\n            },\n        },\n    ],\n    [\n        {\n            user: \"{{user1}}\",\n            content: {\n                text: \"Can you find details about the iPhone 16 release?\",\n            },\n        },\n        {\n            user: \"{{agentName}}\",\n            content: {\n                text: \"Here are the details I found about the iPhone 16 release:\",\n                action: \"WEB_SEARCH\",\n            },\n        },\n    ],\n    [\n        {\n            user: \"{{user1}}\",\n            content: {\n                text: \"What is the schedule for the next FIFA World Cup?\",\n            },\n        },\n        {\n            user: \"{{agentName}}\",\n            content: {\n                text: \"Here is the schedule for the next FIFA World Cup:\",\n                action: \"WEB_SEARCH\",\n            },\n        },\n    ],\n    [\n        {\n            user: \"{{user1}}\",\n            content: { text: \"Check the latest stock price of Tesla.\" },\n        },\n        {\n            user: \"{{agentName}}\",\n            content: {\n                text: \"Here is the latest stock price of Tesla I found:\",\n                action: \"WEB_SEARCH\",\n            },\n        },\n    ],\n    [\n        {\n            user: \"{{user1}}\",\n            content: {\n                text: \"What are the current trending movies in the US?\",\n            },\n        },\n        {\n            user: \"{{agentName}}\",\n            content: {\n                text: \"Here are the current trending movies in the US:\",\n                action: \"WEB_SEARCH\",\n            },\n        },\n    ],\n    [\n        {\n            user: \"{{user1}}\",\n            content: {\n                text: \"What is the latest score in the NBA finals?\",\n            },\n        },\n        {\n            user: \"{{agentName}}\",\n            content: {\n                text: \"Here is the latest score from the NBA finals:\",\n                action: \"WEB_SEARCH\",\n            },\n        },\n    ],\n    [\n        {\n            user: \"{{user1}}\",\n            content: { text: \"When is the next Apple keynote event?\" },\n        },\n        {\n            user: \"{{agentName}}\",\n            content: {\n                text: \"Here is the information about the next Apple keynote event:\",\n                action: \"WEB_SEARCH\",\n            },\n        },\n    ],\n];\n","import { elizaLogger } from \"@elizaos/core\";\nimport { SearchResponse, ScrapeResponse } from \"./types\";\n\nconst BASE_URL = \"https://api.firecrawl.dev/v1\";\n\nexport const createFirecrawlService = (apiKey: string) => {\n    const getScrapeData = async (url: string): Promise<ScrapeResponse> => {\n        if (!apiKey || !url) {\n            throw new Error(\"Invalid parameters: API key and URL are required\");\n        }\n\n        try {\n            const response = await fetch(`${BASE_URL}/scrape`, {\n                method: \"POST\",\n                headers: {\n                    Authorization: `Bearer ${apiKey}`,\n                    \"Content-Type\": \"application/json\",\n                },\n                body: JSON.stringify({\n                    url,\n                }),\n            });\n\n            elizaLogger.info(\"response: \", response);\n\n            console.log(\"data: \", response);\n\n            const data = await response.json();\n            return data;\n        } catch (error: any) {\n            console.error(\"FireCrawl API Error:\", error.message);\n            throw error;\n        }\n    };\n\n    const getSearchData = async (query: string): Promise<SearchResponse> => {\n        if (!apiKey || !query) {\n            throw new Error(\n                \"Invalid parameters: API key and query are required\"\n            );\n        }\n\n        try {\n            const response = await fetch(`${BASE_URL}/search`, {\n                method: \"POST\",\n                headers: {\n                    Authorization: `Bearer ${apiKey}`,\n                    \"Content-Type\": \"application/json\",\n                },\n                body: JSON.stringify({\n                    query,\n                }),\n            });\n\n            elizaLogger.info(\"response: \", response);\n\n            const data = await response.json();\n            return data;\n        } catch (error: any) {\n            console.error(\"FireCrawl API Error:\", error.message);\n            throw error;\n        }\n    };\n\n    return { getSearchData, getScrapeData };\n};\n","export const searchDataPrompt = `\nYou are an expert in summarising data fetched from firecrawl search data scrapper used to search for data on the internet. There would be links and data and mentadata which you have to use to give a meaningful response\n`;\n\nexport const scrapeDataPrompt = `\nYou are an expert in summarising data fetched from firecrawl scrape data scrapper used to scrape data from a website. There would be links and data and mentadata which you have to use to give a meaningful response\n`;\n","import {\n    elizaLogger,\n    Action,\n    ActionExample,\n    HandlerCallback,\n    IAgentRuntime,\n    Memory,\n    State,\n    generateText,\n} from \"@elizaos/core\";\nimport { validateFirecrawlConfig } from \"../environment\";\nimport { getScrapedDataExamples } from \"../examples\";\nimport { createFirecrawlService } from \"../services\";\nimport { extractUrl } from \"../utils\";\nimport { scrapeDataPrompt } from \"../templates\";\nimport { ModelClass } from \"@elizaos/core\";\n\nexport const getScrapeDataAction: Action = {\n    name: \"FIRECRAWL_GET_SCRAPED_DATA\",\n    similes: [\n        \"SCRAPE_WEBSITE\",\n        \"LOOKUP\",\n        \"RETURN_DATA\",\n        \"FIND_ONLINE\",\n        \"QUERY\",\n        \"FETCH_PAGE\",\n        \"EXTRACT_CONTENT\",\n        \"GET_WEBPAGE\",\n        \"CRAWL_SITE\",\n        \"READ_WEBPAGE\",\n        \"PARSE_URL\",\n        \"GET_SITE_DATA\",\n        \"RETRIEVE_PAGE\",\n        \"SCAN_WEBSITE\",\n        \"ANALYZE_URL\",\n    ],\n    description:\n        \"Used to scrape information from a website related to the message, summarize it and return a response. If you need info about something give a link and the plugin will scrape the data from the website and return a response.\",\n    validate: async (runtime: IAgentRuntime) => {\n        await validateFirecrawlConfig(runtime);\n        return true;\n    },\n    handler: async (\n        runtime: IAgentRuntime,\n        message: Memory,\n        state: State,\n        _options: { [key: string]: unknown },\n        callback: HandlerCallback\n    ) => {\n        const config = await validateFirecrawlConfig(runtime);\n        const firecrawlService = createFirecrawlService(\n            config.FIRECRAWL_API_KEY\n        );\n\n        try {\n            const messageText = message.content.text || \"\";\n            const { url } = extractUrl(messageText);\n\n            if (!url) {\n                callback({\n                    text: \"No URL found in the message content.\",\n                });\n                return false;\n            }\n\n            elizaLogger.info(`Found URL: ${url}`);\n            const scrapeData = await firecrawlService.getScrapeData(url);\n            console.log(\"Final scrapeData: \", scrapeData);\n            elizaLogger.success(`Successfully fectched crawl data`);\n\n            const responseText = await generateText({\n                runtime,\n                context: `This was the user question: ${message.content.text}\n\n                        The Response data from firecrawl Scrape Data API is given below\n\n                        ${JSON.stringify(scrapeData)}\n\n                        Now Summarise and use this data and provide a response to question asked in the format.\n                        Note: The response should be in the same language as the question asked and should be human readable and make sense to the user\n                        Do not add any other text or comments to the response just the answer to the question\n                        Remove \\n \\r, special characters and html tags from the response\n                        `,\n                modelClass: ModelClass.SMALL,\n                customSystemPrompt: scrapeDataPrompt,\n            });\n\n            if (callback) {\n                elizaLogger.info(\"response: \", scrapeData);\n                callback({\n                    text: `Scraped data: ${JSON.stringify(responseText)}`,\n                });\n                return true;\n            }\n        } catch (error: any) {\n            elizaLogger.error(\"Error in the Firecrawl plugin\", error);\n            callback({\n                text: `Error fetching scrape data: ${error.message}`,\n                content: { error: error.message },\n            });\n            return false;\n        }\n    },\n    examples: getScrapedDataExamples as ActionExample[][],\n} as Action;\n","interface ParsedUrl {\n    url: string | null;\n    originalText: string;\n}\n\nexport function extractUrl(text: string): ParsedUrl {\n    const urlPattern =\n        /\\b(?:(?:https?|ftp):\\/\\/)?(?:www\\.)?(?:[a-zA-Z0-9-]+\\.)+[a-zA-Z]{2,}(?:\\/[^\\s\\)]*)?/i;\n\n    const match = text.match(urlPattern);\n\n    if (!match) {\n        return {\n            url: null,\n            originalText: text,\n        };\n    }\n\n    // Normalize the URL\n    let url = match[0].trim();\n\n    // If URL starts with www., add https://\n    if (url.startsWith(\"www.\")) {\n        url = `https://${url}`;\n    }\n    // If URL doesn't have any protocol, add https://\n    else if (!url.match(/^[a-zA-Z]+:\\/\\//)) {\n        url = `https://${url}`;\n    }\n\n    return {\n        url,\n        originalText: text,\n    };\n}\n","import { Plugin } from \"@elizaos/core\";\nimport { getSearchDataAction } from \"./actions/getSearchData\";\nimport { getScrapeDataAction } from \"./actions/getScrapeData\";\n\nexport const firecrawlPlugin: Plugin = {\n    name: \"firecrawl\",\n    description: \"Firecrawl plugin for Eliza\",\n    actions: [getSearchDataAction, getScrapeDataAction],\n    // evaluators analyze the situations and actions taken by the agent. they run after each agent action\n    // allowing the agent to reflect on what happened and potentially trigger additional actions or modifications\n    evaluators: [],\n    // providers supply information and state to the agent's context, help agent access necessary data\n    providers: [],\n};\nexport default firecrawlPlugin;\n"],"mappings":";AAAA;AAAA,EACI,eAAAA;AAAA,EAOA;AAAA,OAGG;;;ACRP,SAAS,SAAS;AAEX,IAAM,qBAAqB,EAAE,OAAO;AAAA,EACvC,mBAAmB,EAAE,OAAO,EAAE,IAAI,GAAG,+BAA+B;AACxE,CAAC;AAID,eAAsB,wBAClB,SACwB;AACxB,MAAI;AACA,UAAM,SAAS;AAAA,MACX,mBAAmB,QAAQ,WAAW,mBAAmB;AAAA,IAC7D;AACA,YAAQ,IAAI,YAAY,MAAM;AAC9B,WAAO,mBAAmB,MAAM,MAAM;AAAA,EAC1C,SAAS,OAAO;AACZ,YAAQ,IAAI,aAAa,KAAK;AAC9B,QAAI,iBAAiB,EAAE,UAAU;AAC7B,YAAM,gBAAgB,MAAM,OACvB,IAAI,CAAC,QAAQ,GAAG,IAAI,KAAK,KAAK,GAAG,CAAC,KAAK,IAAI,OAAO,EAAE,EACpD,KAAK,IAAI;AACd,YAAM,IAAI;AAAA,QACN;AAAA,EAAmD,aAAa;AAAA,MACpE;AAAA,IACJ;AACA,UAAM;AAAA,EACV;AACJ;;;AC9BO,IAAM,yBAA4C;AAAA,EACrD;AAAA,IACI;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,MACV;AAAA,IACJ;AAAA,IACA;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,QACN,QAAQ;AAAA,MACZ;AAAA,IACJ;AAAA,EACJ;AAAA,EACA;AAAA,IACI;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,MACV;AAAA,IACJ;AAAA,IACA;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,QACN,QAAQ;AAAA,MACZ;AAAA,IACJ;AAAA,EACJ;AAAA,EACA;AAAA,IACI;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,MACV;AAAA,IACJ;AAAA,IACA;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,MACV;AAAA,IACJ;AAAA,IACA;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,MACV;AAAA,IACJ;AAAA,IACA;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,QACN,QAAQ;AAAA,MACZ;AAAA,IACJ;AAAA,EACJ;AACJ;AAEO,IAAM,wBAA2C;AAAA,EACpD;AAAA,IACI;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,MACV;AAAA,IACJ;AAAA,IACA;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,QACN,QAAQ;AAAA,MACZ;AAAA,IACJ;AAAA,EACJ;AAAA,EACA;AAAA,IACI;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,MACV;AAAA,IACJ;AAAA,IACA;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,QACN,QAAQ;AAAA,MACZ;AAAA,IACJ;AAAA,EACJ;AAAA,EACA;AAAA,IACI;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,MACV;AAAA,IACJ;AAAA,IACA;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,QACN,QAAQ;AAAA,MACZ;AAAA,IACJ;AAAA,EACJ;AAAA,EACA;AAAA,IACI;AAAA,MACI,MAAM;AAAA,MACN,SAAS,EAAE,MAAM,yCAAyC;AAAA,IAC9D;AAAA,IACA;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,QACN,QAAQ;AAAA,MACZ;AAAA,IACJ;AAAA,EACJ;AAAA,EACA;AAAA,IACI;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,MACV;AAAA,IACJ;AAAA,IACA;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,QACN,QAAQ;AAAA,MACZ;AAAA,IACJ;AAAA,EACJ;AAAA,EACA;AAAA,IACI;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,MACV;AAAA,IACJ;AAAA,IACA;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,QACN,QAAQ;AAAA,MACZ;AAAA,IACJ;AAAA,EACJ;AAAA,EACA;AAAA,IACI;AAAA,MACI,MAAM;AAAA,MACN,SAAS,EAAE,MAAM,wCAAwC;AAAA,IAC7D;AAAA,IACA;AAAA,MACI,MAAM;AAAA,MACN,SAAS;AAAA,QACL,MAAM;AAAA,QACN,QAAQ;AAAA,MACZ;AAAA,IACJ;AAAA,EACJ;AACJ;;;ACpKA,SAAS,mBAAmB;AAG5B,IAAM,WAAW;AAEV,IAAM,yBAAyB,CAAC,WAAmB;AACtD,QAAM,gBAAgB,OAAO,QAAyC;AAClE,QAAI,CAAC,UAAU,CAAC,KAAK;AACjB,YAAM,IAAI,MAAM,kDAAkD;AAAA,IACtE;AAEA,QAAI;AACA,YAAM,WAAW,MAAM,MAAM,GAAG,QAAQ,WAAW;AAAA,QAC/C,QAAQ;AAAA,QACR,SAAS;AAAA,UACL,eAAe,UAAU,MAAM;AAAA,UAC/B,gBAAgB;AAAA,QACpB;AAAA,QACA,MAAM,KAAK,UAAU;AAAA,UACjB;AAAA,QACJ,CAAC;AAAA,MACL,CAAC;AAED,kBAAY,KAAK,cAAc,QAAQ;AAEvC,cAAQ,IAAI,UAAU,QAAQ;AAE9B,YAAM,OAAO,MAAM,SAAS,KAAK;AACjC,aAAO;AAAA,IACX,SAAS,OAAY;AACjB,cAAQ,MAAM,wBAAwB,MAAM,OAAO;AACnD,YAAM;AAAA,IACV;AAAA,EACJ;AAEA,QAAM,gBAAgB,OAAO,UAA2C;AACpE,QAAI,CAAC,UAAU,CAAC,OAAO;AACnB,YAAM,IAAI;AAAA,QACN;AAAA,MACJ;AAAA,IACJ;AAEA,QAAI;AACA,YAAM,WAAW,MAAM,MAAM,GAAG,QAAQ,WAAW;AAAA,QAC/C,QAAQ;AAAA,QACR,SAAS;AAAA,UACL,eAAe,UAAU,MAAM;AAAA,UAC/B,gBAAgB;AAAA,QACpB;AAAA,QACA,MAAM,KAAK,UAAU;AAAA,UACjB;AAAA,QACJ,CAAC;AAAA,MACL,CAAC;AAED,kBAAY,KAAK,cAAc,QAAQ;AAEvC,YAAM,OAAO,MAAM,SAAS,KAAK;AACjC,aAAO;AAAA,IACX,SAAS,OAAY;AACjB,cAAQ,MAAM,wBAAwB,MAAM,OAAO;AACnD,YAAM;AAAA,IACV;AAAA,EACJ;AAEA,SAAO,EAAE,eAAe,cAAc;AAC1C;;;ACjEO,IAAM,mBAAmB;AAAA;AAAA;AAIzB,IAAM,mBAAmB;AAAA;AAAA;;;AJYhC,SAAS,kBAAkB;AAEpB,IAAM,sBAA8B;AAAA,EACvC,MAAM;AAAA,EACN,SAAS;AAAA,IACL;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACJ;AAAA,EACA,aACI;AAAA,EACJ,UAAU,OAAO,YAA2B;AACxC,UAAM,wBAAwB,OAAO;AACrC,WAAO;AAAA,EACX;AAAA,EACA,SAAS,OACL,SACA,SACA,OACA,UACA,aACC;AACD,UAAM,SAAS,MAAM,wBAAwB,OAAO;AACpD,UAAM,mBAAmB;AAAA,MACrB,OAAO;AAAA,IACX;AAEA,YAAQ,IAAI,QAAQ,QAAQ,IAAI;AAChC,QAAI;AACA,YAAM,cAAc,QAAQ,QAAQ,QAAQ;AAE5C,MAAAC,aAAY,KAAK,eAAe,WAAW,EAAE;AAC7C,YAAM,aACF,MAAM,iBAAiB,cAAc,WAAW;AAEpD,MAAAA,aAAY,QAAQ,4BAA4B;AAEhD,YAAM,eAAe,MAAM,aAAa;AAAA,QACpC;AAAA,QACA,SAAS,+BAA+B,QAAQ,QAAQ,IAAI;AAAA;AAAA;AAAA;AAAA,0BAIlD,KAAK,UAAU,UAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QAOpC,YAAY,WAAW;AAAA,QACvB,oBAAoB;AAAA,MACxB,CAAC;AAED,cAAQ,IAAI,gBAAgB,YAAY;AAMxC,UAAI,UAAU;AACV,iBAAS;AAAA,UACL,MAAM,GAAG,KAAK,UAAU,YAAY,CAAC;AAAA,QACzC,CAAC;AACD,eAAO;AAAA,MACX;AAAA,IACJ,SAAS,OAAY;AACjB,MAAAA,aAAY,MAAM,iCAAiC,KAAK;AACxD,eAAS;AAAA,QACL,MAAM,8BAA8B,MAAM,OAAO;AAAA,QACjD,SAAS,EAAE,OAAO,MAAM,QAAQ;AAAA,MACpC,CAAC;AACD,aAAO;AAAA,IACX;AAAA,EACJ;AAAA,EACA,UAAU;AACd;;;AKlGA;AAAA,EACI,eAAAC;AAAA,EAOA,gBAAAC;AAAA,OACG;;;ACJA,SAAS,WAAW,MAAyB;AAChD,QAAM,aACF;AAEJ,QAAM,QAAQ,KAAK,MAAM,UAAU;AAEnC,MAAI,CAAC,OAAO;AACR,WAAO;AAAA,MACH,KAAK;AAAA,MACL,cAAc;AAAA,IAClB;AAAA,EACJ;AAGA,MAAI,MAAM,MAAM,CAAC,EAAE,KAAK;AAGxB,MAAI,IAAI,WAAW,MAAM,GAAG;AACxB,UAAM,WAAW,GAAG;AAAA,EACxB,WAES,CAAC,IAAI,MAAM,iBAAiB,GAAG;AACpC,UAAM,WAAW,GAAG;AAAA,EACxB;AAEA,SAAO;AAAA,IACH;AAAA,IACA,cAAc;AAAA,EAClB;AACJ;;;ADnBA,SAAS,cAAAC,mBAAkB;AAEpB,IAAM,sBAA8B;AAAA,EACvC,MAAM;AAAA,EACN,SAAS;AAAA,IACL;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACJ;AAAA,EACA,aACI;AAAA,EACJ,UAAU,OAAO,YAA2B;AACxC,UAAM,wBAAwB,OAAO;AACrC,WAAO;AAAA,EACX;AAAA,EACA,SAAS,OACL,SACA,SACA,OACA,UACA,aACC;AACD,UAAM,SAAS,MAAM,wBAAwB,OAAO;AACpD,UAAM,mBAAmB;AAAA,MACrB,OAAO;AAAA,IACX;AAEA,QAAI;AACA,YAAM,cAAc,QAAQ,QAAQ,QAAQ;AAC5C,YAAM,EAAE,IAAI,IAAI,WAAW,WAAW;AAEtC,UAAI,CAAC,KAAK;AACN,iBAAS;AAAA,UACL,MAAM;AAAA,QACV,CAAC;AACD,eAAO;AAAA,MACX;AAEA,MAAAC,aAAY,KAAK,cAAc,GAAG,EAAE;AACpC,YAAM,aAAa,MAAM,iBAAiB,cAAc,GAAG;AAC3D,cAAQ,IAAI,sBAAsB,UAAU;AAC5C,MAAAA,aAAY,QAAQ,kCAAkC;AAEtD,YAAM,eAAe,MAAMC,cAAa;AAAA,QACpC;AAAA,QACA,SAAS,+BAA+B,QAAQ,QAAQ,IAAI;AAAA;AAAA;AAAA;AAAA,0BAIlD,KAAK,UAAU,UAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QAOpC,YAAYF,YAAW;AAAA,QACvB,oBAAoB;AAAA,MACxB,CAAC;AAED,UAAI,UAAU;AACV,QAAAC,aAAY,KAAK,cAAc,UAAU;AACzC,iBAAS;AAAA,UACL,MAAM,iBAAiB,KAAK,UAAU,YAAY,CAAC;AAAA,QACvD,CAAC;AACD,eAAO;AAAA,MACX;AAAA,IACJ,SAAS,OAAY;AACjB,MAAAA,aAAY,MAAM,iCAAiC,KAAK;AACxD,eAAS;AAAA,QACL,MAAM,+BAA+B,MAAM,OAAO;AAAA,QAClD,SAAS,EAAE,OAAO,MAAM,QAAQ;AAAA,MACpC,CAAC;AACD,aAAO;AAAA,IACX;AAAA,EACJ;AAAA,EACA,UAAU;AACd;;;AEpGO,IAAM,kBAA0B;AAAA,EACnC,MAAM;AAAA,EACN,aAAa;AAAA,EACb,SAAS,CAAC,qBAAqB,mBAAmB;AAAA;AAAA;AAAA,EAGlD,YAAY,CAAC;AAAA;AAAA,EAEb,WAAW,CAAC;AAChB;AACA,IAAO,gBAAQ;","names":["elizaLogger","elizaLogger","elizaLogger","generateText","ModelClass","elizaLogger","generateText"]}